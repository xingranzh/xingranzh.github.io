<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en">

<head>
<title>Xingran Zhou's Personal Page</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta property="og:title" content="Xingran Zhou's Personal Page"/>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-154138547-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-154138547-1');
</script>


<script type="text/javascript">
// redefining default features
var _POPUP_FEATURES = 'width=500,height=300,resizable=1,scrollbars=1,titlebar=1,status=1';
</script>


<link media="all" href="style.css" type="text/css" rel="StyleSheet">
<style type="text/css" media="all">
IMG {
	PADDING-RIGHT: 0px;
	PADDING-LEFT: 0px;
	FLOAT: right;
	PADDING-BOTTOM: 0px;
	PADDING-TOP: 0px
}
#primarycontent {
	MARGIN-LEFT: auto; ; WIDTH: expression(document.body.clientWidth >
1000? "1000px": "auto" ); MARGIN-RIGHT: auto; TEXT-ALIGN: left; max-width:
1000px }
BODY {
	TEXT-ALIGN: center
}
</style>

<meta content="MSHTML 6.00.2800.1400" name="GENERATOR"><script src="b5m.js" id="b5mmain" type="text/javascript"></script>
</head>


<body>
<div id="primarycontent">


<h1><strong> Xingran Zhou &nbsp;&nbsp;&nbsp;&nbsp; <span lang="zh-Hans"><font style ="font-family:Microsoft JhengHei ">周星然 </font></span></strong></h1>

<div>
<h3>Ph.D. student</h3>
<h3>Zhejiang University, Hangzhou City, P.R.China</h3>
<h3>Email: xingranzh AT zju.edu.cn</h3>
</div>

<br>
<br>

<h1>Biography</h1>
<div style="font-size: 15px"><p align="justify">Xingran Zhou is a Ph.D. student at <a href="http://www.zju.edu.cn/english/2018/0521/c19590a812438/page.htm">Zhejiang University</a>, Hangzhou City, China. He is under the supervision of <a href="http://www.cs.binghamton.edu/~zhongfei/">Professor Zhongfei Zhang</a>.
</div>

<div style="font-size: 15px"><p align="justify">
<!-- His research interests focus on deep learning and computer vision. He is particularly interested in generative models, as well as generative adversarial networks (GANs) and its application. -->
His research interests focus on the intersection of Computer Vision and Computer Graphics. He is particularly interested in learning-based models for generating appealing visuals.
</div>

<div style="font-size: 15px"><p align="justify">
He is doing a research internship in <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research – Asia (MSRA)</a> from July 2019.</p>
</div>

<br>
<br>

<div style="font-size: 15px"><p align="justify">
LinkedIn Page: <a href="https://www.linkedin.com/in/xingranzh/">https://www.linkedin.com/in/xingranzh/</a>
</p>
</div>

<br>
<br>


<h1>Publication</h1>
<table width="100%" border="0" cellspacing="50" cellpadding="10" >
	<tr>
		<td width="40%" class="full">
			<img src="images/cvpr21.png" style="width:100%;" align="middle">
		</td >
		<td width="60%" class="full">
            <h2><strong>Full-Resolution Correspondence Learning for Image Translation</strong></h2>
            <br>
            <p style="text-align:justify">
                <strong>Xingran Zhou</strong>, Bo Zhang, Ting Zhang, Pan Zhang, Jianmin Bao, Dong Chen, Zhongfei Zhang, Fang Wen
            </p>
            <p style="text-align:justify">
                <strong>CVPR 2021</strong>, <strong><font color="red">oral presentation</font></strong>, <br>
                <a href="http://cvpr2021.thecvf.com/node/290"><strong><font color="red">Best Paper Candidate (ID: 3592)</font></strong></a>
            </p>
            <p style="text-align:left">
                <a href="https://github.com/microsoft/CoCosNet-v2">[Code]</a>&nbsp;&nbsp;&nbsp;
                <a href="https://arxiv.org/pdf/2012.02047.pdf">[arXiv]</a>&nbsp;&nbsp;&nbsp;
                <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_CoCosNet_v2_Full-Resolution_Correspondence_Learning_for_Image_Translation_CVPR_2021_paper.pdf">[pdf]</a>&nbsp;&nbsp;&nbsp;
                <a href="bibtex/full-res-corr.txt">[BibTex]</a>&nbsp;&nbsp;&nbsp;<br>
                <a href="https://github.com/xingranzh/xingranzh.github.io/blob/master/slides/cocosnet_v2_slides.pdf">[Slides]</a>&nbsp;&nbsp;&nbsp;
                <a href="https://mp.weixin.qq.com/s/VUQiOmryQU1nT9sUdVqnQg">[Intro in Chinese]</a>&nbsp;&nbsp;&nbsp;
            </p>
            <div style="font-size: 5px"><p align="justify">
            </p>
		</td>
    </tr>

	<tr>
		<td width="40%" class="full">
			<img src="images/cvpr19.png" style="width:100%;" align="middle">
		</td >
		<td width="60%" class="full">
            <h2><strong>Text Guided Person Image Synthesis</strong></h2>
            <br>
            <p style="text-align:justify">
                <strong>Xingran Zhou</strong>, Siyu Huang, Yingming Li, Bin Li, Jiachen Li, Zhongfei Zhang
            </p>
            <p style="text-align:justify">
                <strong>CVPR 2019</strong> (acceptance rate 25.2%)
            </p>

            <p style="text-align:left">
                <a href="https://arxiv.org/pdf/1904.05118.pdf">[arXiv]</a>&nbsp;&nbsp;&nbsp;
                <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhou_Text_Guided_Person_Image_Synthesis_CVPR_2019_paper.pdf">[pdf]</a>&nbsp;&nbsp;&nbsp;
                <a href="bibtex/cvpr19.txt">[BibTex]</a>
            </p>

            <div style="font-size: 5px"><p align="justify">
                We present a novel method to manipulate the visual appearance (pose and attribute) of a person image according to natural language descriptions.
            </p>
		</td>
    </tr>

	<tr>
		<td width="40%" class="full">
			<img src="images/ijcai20.png" style="width:100%;" align="middle">
		</td >
		<td width="60%" class="full">
            <h2><strong>Generating Person Images with Appearance-aware Pose Stylizer</strong></h2>
            <br>
            <p style="text-align:justify">
                Siyu Huang, Haoyi Xiong, Zhi-Qi Cheng, Qingzhong Wang, <strong>Xingran Zhou</strong>, Bihan Wen, Jun Huan, Dejing Dou
            </p>
            <p style="text-align:justify">
                International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2020 (acceptance rate 12.6%)
            </p>

            <p style="text-align:left">
                <a href="https://github.com/siyuhuang/PoseStylizer">[Code]</a>&nbsp;&nbsp;&nbsp;
                <a href="https://arxiv.org/pdf/2007.09077.pdf">[arXiv]</a>&nbsp;&nbsp;&nbsp;
                <a href="https://www.ijcai.org/Proceedings/2020/0087.pdf">[pdf]</a>&nbsp;&nbsp;&nbsp;
                <a href="bibtex/ijcai20.txt">[BibTex]</a>
            </p>

            <div style="font-size: 5px"><p align="justify">
                We present a novel generator called Appearance-aware Pose Stylizer (APS) which generates human images by coupling the target pose with the conditioned person appearance progressively.
            </p>
		</td>
	</tr>
</table>

<br>
<br>

</div>

</body>
</html>
